<!doctype html><html xmlns=http://www.w3.org/1999/xhtml lang=es-es><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Empezando en Spark con Docker | Adrián Abreu</title><meta property="og:title" content="Empezando en Spark con Docker - Adrián Abreu"><meta property="og:description" content="A pesar de haber leído guías tan buenas como:
https://medium.com/@bogdan.cojocar/how-to-run-scala-and-spark-in-the-jupyter-notebook-328a80090b3b
https://medium.com/@singhpraveen2010/install-apache-spark-and-configure-with-jupyter-notebook-in-10-minutes-ae120ebca597
Se me ha hecho cuesta arriba el poder conectar un notebook de jupyter y utilizar Scala. Entre configurar el apache toree para poder usar scala en los notebooks y algún error luego en spark al usarlo desde IntelliJ, me he acabado rindiendo.
Nota del autor: Como disclaimer esto ocurre probablemente porque estoy en Manjaro y mi version de Scala es incompatible."><meta property="og:url" content="https://adrianabreu.github.io/blog/2019-11-10-empezando-en-spark-con-docker/"><meta property="og:site_name" content="Adrián Abreu"><meta property="og:type" content="article"><meta property="og:image" content="https://www.gravatar.com/avatar/9fda37f7195de6954a6d4f525eff01ee?s=256"><meta property="article:section" content="Blog"><meta property="article:tag" content="Spark"><meta property="article:tag" content="Docker"><meta property="article:published_time" content="2019-11-09T19:22:32Z"><meta property="article:modified_time" content="2019-11-09T19:22:32Z"><meta name=twitter:card content="summary"><meta name=twitter:site content="@aabreuglez"><meta name=twitter:creator content="@aabreuglez"><link href=https://adrianabreu.github.io/index.xml rel=alternate type=application/rss+xml title="Adrián Abreu"><link rel=stylesheet href=/css/style.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://adrianabreu.github.io/blog/2019-11-10-empezando-en-spark-con-docker/><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"></head><body><section class=section><div class=container><nav id=nav-main class=nav><div id=nav-name class=nav-left><a id=nav-anchor class=nav-item href=https://adrianabreu.github.io><h1 id=nav-heading class="title is-4">Adrián Abreu</h1></a></div><div class=nav-right><nav id=nav-items class="nav-item level is-mobile"><a class=level-item aria-label=github href=https://github.com/adrianabreu target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></i></span></a><a class=level-item aria-label=twitter href=https://twitter.com/aabreuglez target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></i></span></a><a class=level-item aria-label=email href=mailto:aabreuglez@gmail.com target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></i></span></a><a class=level-item aria-label=linkedin href=https://linkedin.com/in/AdrianAbreu target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path stroke-width="1.8" d="m5.839218 4.101561c0 1.211972-.974141 2.194011-2.176459 2.194011S1.4863 5.313533 1.4863 4.101561c0-1.211094.974141-2.194011 2.176459-2.194011s2.176459.982917 2.176459 2.194011zm.017552 3.94922H1.468748v14.04167H5.85677V8.050781zm7.005038.0H8.501869v14.04167h4.360816v-7.370999c0-4.098413 5.291077-4.433657 5.291077.0v7.370999h4.377491v-8.89101c0-6.915523-7.829986-6.66365-9.669445-3.259423V8.050781z"/></svg></i></span></a></nav></div></nav><nav class=nav></nav></div><script src=/js/navicon-shift.js></script></section><section class=section><div class=container><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/spark/>#Spark</a>
| <a class="subtitle is-6" href=/tags/docker/>#Docker</a></div><h2 class="subtitle is-6">November 9, 2019</h2><h1 class=title>Empezando en Spark con Docker</h1><div class=content><p>A pesar de haber leído guías tan buenas como:</p><p><a href=https://medium.com/@bogdan.cojocar/how-to-run-scala-and-spark-in-the-jupyter-notebook-328a80090b3b>https://medium.com/@bogdan.cojocar/how-to-run-scala-and-spark-in-the-jupyter-notebook-328a80090b3b</a></p><p><a href=https://medium.com/@singhpraveen2010/install-apache-spark-and-configure-with-jupyter-notebook-in-10-minutes-ae120ebca597>https://medium.com/@singhpraveen2010/install-apache-spark-and-configure-with-jupyter-notebook-in-10-minutes-ae120ebca597</a></p><p>Se me ha hecho cuesta arriba el poder conectar un notebook de jupyter y utilizar Scala. Entre configurar el apache toree para poder usar scala en los notebooks y algún error luego en spark al usarlo desde IntelliJ, me he acabado rindiendo.</p><p><em>Nota del autor:</em> Como disclaimer esto ocurre probablemente porque estoy en Manjaro y mi version de Scala es incompatible. Esta clase de problemas en su día las solucionaba fijando una versión, sin embargo, creo que teniendo una herramienta tan potente como es Docker estoy reinventando la rueda par un problema ya resuelto. Además de que voy a probarlo también en un windows para ver que es una solución agnóstical SO.</p><p>No voy a profundizar en nada de docker, simplemente podemos verlo como una &ldquo;virtualización ligera&rdquo; que se alimenta de imágenes para ejecutar procesos. Para el caso de configurar Spark con Jupyter podemos utilizar esta imagen de docker para nuestro propósito: <a href=https://hub.docker.com/r/jupyter/all-spark-notebook/>https://hub.docker.com/r/jupyter/all-spark-notebook/</a></p><p>Tras ejecutar el comando <code>docker pull jupyter/all-spark-notebook</code> y descargar los 2 GB de imagen:</p><img src=/images/spark-sample/pullingimage.png class=img-responsive><p>Ya solo nos quedaría arrancar el proceso. Para esto tenemos que mapear tres puertos del entorno de docker a nuestra máquina. Esto se hace en el propio comando de arranque</p><p><code>docker run -p 8888:8888/tcp -p 4040:4040/tcp jupyter/all-spark-notebook</code></p><img src=/images/spark-sample/runwithports.png class=img-responsive><p>Si copiamos la url que nos aparece, haremos el token de forma automática y podremos acceder a los notebook y ejecutar comandos de scala:</p><img src=/images/spark-sample/jupyter.png class=img-responsive><p>Y además en el puerto 4040 tendremos la spark ui para revisar nuestras ejecuciones:</p><img src=/images/spark-sample/sparkui.png class=img-responsive><p>Con esto, ya podemos practicar con Spark sin afectar a la configuración que tengamos en nuestra máquina.</p><h2 id=extra>Extra</h2><p>De forma opcional, vamos a montar un directorio en docker y vamos a ejecutar un job en Spark utilizando el comando spark-submit.</p><p>Lo primero, es que si estamos en Windows debemos compartir nuestro disco con docker, simplemente vamos a Settings -> Shared Drivers y habilitamos el disco.</p><img src=/images/spark-sample/sharingdrives.png class=img-responsive><p>Ahora necesitamos montar el directorio y esto lo haremos al arrancar la imagen. El comando sería:</p><p><code>docker run -p 8888:8888/tcp -p 4040:4040/tcp -v c:/spark-demo:/data jupyter/all-spark-notebook</code></p><p>Y en el notebook de jupyter abrimos una terminal para validarlo:</p><img src=/images/spark-sample/mounttable.png class=img-responsive><p>Ahora que ya tenemos esto, la idea es ver como sería un entorno &ldquo;productivo&rdquo; de Spark, más allá de los notebooks y mandar un spark job utilizando el punto de entrada de spark submit.</p><p>Nuestro programa no hará gran cosa, solo se trata de una aplicación de Scala que genera 500 numeros y los cuenta según sean múltiplos de 3 o no. (No hay que centrarse en el código). La parte más importante es que necesitamos mandar un assembly jar. Es decir, un jar que contiene sus dependencias. Todo esto está documentado por Spark aquí: <a href=https://spark.apache.org/docs/latest/submitting-applications.html>https://spark.apache.org/docs/latest/submitting-applications.html</a></p><p>Para poder crear el assembly vamos a utilizar sbt y el plugin <a href=https://github.com/sbt/sbt-assembly>https://github.com/sbt/sbt-assembly</a></p><p>Para poder dejar el articulo más ligero os dejo un enlace al repositorio de github con el código.</p><p><a href=https://github.com/adrianabreu/spark-multiple-of-3>https://github.com/adrianabreu/spark-multiple-of-3</a></p><p>Simplemente tenemos que ejecutar el comando &ldquo;sbt assembly&rdquo; para generar un jar y este jar lo ponemos en la carpeta del docker.</p><p>Ahora utilizaremos el comando de spark-submit para mandar el job.</p><p><code>/usr/local/spark/bin/spark-submit --class "example.Application" multiple-of-3-assembly-1.0.0.jar</code></p><p>Et voilá!</p><img src=/images/spark-sample/sparksubmit.png class=img-responsive><h2 id=faq>FAQ:</h2><p>Si hay algún error con puertos y al intentar rearrancar la imagen de docker aparece que los puertos estan en uso, basta con hacer un docker ps -a copiar el container id y hacer un docker kill containerid.</p></div></div></section><section class=section><div class="container has-text-centered"><p>2017 Adrián Abreu powered by Hugo and Kiss Theme</p></div></section></body></html>