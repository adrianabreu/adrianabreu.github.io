<!doctype html><html xmlns=http://www.w3.org/1999/xhtml lang=es-es><head><meta name=generator content="Hugo 0.95.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Adrian Abreu Data Engineer Blog</title><meta property="og:title" content="Adrián Abreu"><meta property="og:description" content><meta property="og:url" content="https://adrianabreu.github.io/"><meta property="og:site_name" content="Adrián Abreu"><meta property="og:type" content="website"><meta property="og:image" content="https://www.gravatar.com/avatar/9fda37f7195de6954a6d4f525eff01ee?s=256"><meta property="article:section" content><meta property="og:updated_time" content="2022-03-21T22:28:32Z"><meta name=twitter:card content="summary"><meta name=twitter:site content="@aabreuglez"><meta name=twitter:creator content="@aabreuglez"><link href=https://adrianabreu.github.io/index.xml rel=alternate type=application/rss+xml title="Adrián Abreu"><link rel=stylesheet href=/css/style.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://adrianabreu.github.io/><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"></head><body><section class=section><div class=container><nav id=nav-main class=nav><div id=nav-name class=nav-left><a id=nav-anchor class=nav-item href=https://adrianabreu.github.io><h1 id=nav-heading class="title is-4">Adrián Abreu</h1></a></div><div class=nav-right><nav id=nav-items class="nav-item level is-mobile"><a class=level-item aria-label=github href=https://github.com/adrianabreu target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></i></span></a><a class=level-item aria-label=twitter href=https://twitter.com/aabreuglez target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></i></span></a><a class=level-item aria-label=email href=mailto:aabreuglez@gmail.com target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></i></span></a><a class=level-item aria-label=linkedin href=https://linkedin.com/in/AdrianAbreu target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path stroke-width="1.8" d="m5.839218 4.101561c0 1.211972-.974141 2.194011-2.176459 2.194011S1.4863 5.313533 1.4863 4.101561c0-1.211094.974141-2.194011 2.176459-2.194011s2.176459.982917 2.176459 2.194011zm.017552 3.94922H1.468748v14.04167H5.85677V8.050781zm7.005038.0H8.501869v14.04167h4.360816v-7.370999c0-4.098413 5.291077-4.433657 5.291077.0v7.370999h4.377491v-8.89101c0-6.915523-7.829986-6.66365-9.669445-3.259423V8.050781z"/></svg></i></span></a></nav></div></nav><nav class=nav></nav></div><script src=/js/navicon-shift.js></script></section><section class=section><div class=container><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/data-visualization/>#Data Visualization</a></div><h2 class="subtitle is-6 date">January 4, 2021</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2021-01-04-notes-storytelling-with-data-/>Notas sobre storytelling with data</a></h1><div class=content>Como uno de los objetivos antes de cambiar de año quería empezar a dar visibilidad sobre el producto en el que estoy trabajando con un dashboard. Tras probar varias opciones, hemos optado por utilizar Quicksight para simplificar los procesos en aws y reducir nuestra infraestructura.
Aún así, empezando un dashboard de cero, es muy difícil transmitir la información de forma clara. Es importante evitar que los usuarios vengan simplemente a expotar sus datos a csv para luego cargarlos en excel.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2021-01-04-notes-storytelling-with-data-/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/python/>#Python</a>
| <a class="subtitle is-6" href=/tags/poetry/>#Poetry</a></div><h2 class="subtitle is-6 date">December 30, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-12-30-configurando-poetry-gitlab/>Configurando poetry y gitlab</a></h1><div class=content>Hace poco más de un mes cambié de trabajo y me encontré además con un cambio de stack considerable. Ahora estoy trabajando con aws + github + python. Y bueno, al margen de los cambios de conceptos y demás, me ha llevado bastante encontrar un flujo de trabajo que no me pareciera &ldquo;frágil&rdquo;.
Lo primero y que me ha decepcionado bastante es que github no incluye soporte para hostear paquetes de python.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-12-30-configurando-poetry-gitlab/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/data-factory/>#Data Factory</a></div><h2 class="subtitle is-6 date">October 1, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-10-01-jugando-con-df/>Jugando con Data Factory</a></h1><div class=content>Sorprendentemente, hasta ahora, no había tenido la posibilidad de trabajar con data factory, sólo lo habia usado para algunas migraciones de datos.
Sin embargo, tras estabilizar un proyecto y consolidar su nueva etapa, necesitabamos simplificar la solución implementada para migrar datos.
Una representación sencilla de la arquitectura actual sería:
En un flujo muy sencillo sería esto:
La etl escribe un fichero csv con spark en un directorio de un blob storage.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-10-01-jugando-con-df/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"></div><h2 class="subtitle is-6 date">September 29, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-12-29-spark-joins/>Tipos de join en spark</a></h1><div class=content>Hace unos días tuve la fortuna (o desgracia) de implementar la lógica más compleja de todo el dominio. El resultado, como esperaba, una etl que falaba por recursos constantementes. El problema:
Caused by: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1 Lo primero fue revisar el plan de ejecución para ver que estaba sucediendo.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-12-29-spark-joins/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/spark/>#Spark</a>
| <a class="subtitle is-6" href=/tags/analytics/>#Analytics</a>
| <a class="subtitle is-6" href=/tags/sql/>#SQL</a></div><h2 class="subtitle is-6 date">September 2, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-09-02-calcular-el-domingo-correspondiente/>Calcular el domingo de la semana</a></h1><div class=content>A la hora de publicar reportes es común agrupar los datos por semanas. Otro motivo es alinearse con el negocio donde los cierres pueden producirse en días concretos, por ejemplo, un domingo.
En esos casos si tenemos los datos particionados por días nos interesa saber a que domingo correspondería cada uno de los datos.
Los que venimos de otros entornos tendemos a pensar en esas complicadas librerías de fechas (moment.js, jodatime, etc).
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-09-02-calcular-el-domingo-correspondiente/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/spark/>#Spark</a>
| <a class="subtitle is-6" href=/tags/analytics/>#Analytics</a>
| <a class="subtitle is-6" href=/tags/datalake/>#Datalake</a></div><h2 class="subtitle is-6 date">August 25, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-08-25-detectando-ficheros-pequenos/>Detectando ficheros pequenos Spark</a></h1><div class=content>Uno de los mayores problemas de rendimiento que podemos encontrar en los datalake es tener que mover una enorme cantidad de ficheros pequeños, por el overhead que eso representa en las transacciones. Este post de databricks recomendada https://forums.databricks.com/questions/101/what-is-an-optimal-size-for-file-partitions-using.html que se crearan ficheros de 1GB parquet.
Sin embargo mucha gente no sabe como detectar esto. Hace poco estuve jugando con un notebook y usando simplemente las herramientas del dbutils pude clasificar los ficheros que tenia en las entidades del datalake en múltiples categorías, así podría estimar cuantos ficheros había en un rango de tiempo.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-08-25-detectando-ficheros-pequenos/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/spark/>#Spark</a>
| <a class="subtitle is-6" href=/tags/analytics/>#Analytics</a>
| <a class="subtitle is-6" href=/tags/sql/>#SQL</a></div><h2 class="subtitle is-6 date">August 11, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2020-08-11-spark-windows-functions/>Spark windows functions (I)</a></h1><div class=content>En analítica, es muy común hacer uso de las funciones de ventana para distintos cálculos. Hace poco me encontré con un pequeño problema cuya solución mejoró muchísimo al usar las funciones de ventana, demos un poco de contexto.
Tenemos una dimensión de usuarios donde los usuarios se van registrando con una fecha y tenemos una tabla de ventas donde tenemos las ventas globales para cada día
Y lo que queremos dar es una visión de cómo cada día evoluciona el programa, para ello se quiere que cada día estén tanto las ventas acumuladas como los registros acumulados.
<a class="button is-link" href=https://adrianabreu.github.io/blog/2020-08-11-spark-windows-functions/ style=height:28px>Read more</a></div></article><article><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/spark/>#Spark</a>
| <a class="subtitle is-6" href=/tags/analytics/>#Analytics</a>
| <a class="subtitle is-6" href=/tags/sql/>#SQL</a></div><h2 class="subtitle is-6 date">August 11, 2020</h2><h1 class=title><a href=https://adrianabreu.github.io/blog/2023-01-01-spark-windows-functions-ii/>Spark windows functions (II)</a></h1><div class=content>En el post anterior pudimos utilizar las funciones de ventanas para realizar agregados de sumas sobre ventanas temporales. Ahora, me gustaría utilizar otro ejemplo de analítica: Comparar con datos previos.
Pongamos que queremos analizar las ventas de un producto en diversos periodos de tiempo. Es decir, nos interesa saber si ahora vende más o menos que antes.
Para ello partiremos de una tabla de ventas:
DateKey ProductId Sales Ahora que tenemos esto nos interesaría agrupar para cada producto sus ventas</div></article></div></section><section class=section><div class=container><nav class="level is-mobile"><div class=level-left><div class=level-item><a class=button href=/><span class="icon is-small is-marginless"><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><polyline points="15 18 9 12 15 6"/></svg></span>Newer</a></div></div><div class="level-right is-marginless"><div class=level-item><a class=button href=/page/3/>Older
<span class="icon is-small is-marginless"><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav></div></section><section class=section><div class="container has-text-centered"><p>2017 Adrián Abreu powered by Hugo and Kiss Theme</p></div></section></body></html>